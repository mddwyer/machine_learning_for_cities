{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matt Dwyer (mdd328)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total points for this HW: 100.\n",
    "\n",
    "Please note: Copying and pasting other people's work is absolutely prohibited.  Any such cases will be reported to CUSP's education team and severely punished. Discussion is encouraged, and feel free to exchange ideas with your classmates, but please write your own code and do your own work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Question 1: Accuracy and interpretability (10 pts)\n",
    "\n",
    "a) Describe a real-world prediction problem using urban data for which _interpretability_ of your models and results is essential, and for which it might be preferable to use decision trees rather than random forests.  Argue why this is the case. (3 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Interpretability is important when an industry is highly regulated and in need of checks and approvals. With the potential legal ramifications of what would happen if an alogorithm were to arrive at an incorrect conclusion, such an algorithm would need to be well understood and explainable to many different stakeholders.\n",
    "\n",
    "    For instance, if the city were looking at building and demographic information to determine where to send building inspectors, the leading agency would need to know how such an algorithm works in order to explain  why some buildings were inspected and some were not if public safety incidents occur. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Describe a real-world prediction problem using urban data for which _accuracy_ is paramount and interpretability may be less important, and for which it might be preferable to use random forests rather than decision trees.  Argue why this is the case. (3 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Interpretability would be less important in cases where decision making is more in house and less under scrutiny of governing bodies. For instance, if a ride sharing company were trying to predict which areas to send their drivers to maximize revenue, a more accurate model would be preferable to an interpretable one, as the stakeholders invovled would care about the revenue, and the consequences would not be as drastic as damaging to public safety."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Let's imagine that you want to try to get the best of both worlds (accuracy _and_ interpretability).  So you decide to start by learning a random forest classifier.  Describe at least one way of getting some interpretability out of the model by post-processing.  You could either pick a method from the literature (e.g., Domingos's work on combining multiple models or some method of computing variable importance), or come up with your own approach (doesn't have to be ground-breaking, but feel free to be creative!) (4 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    One way to achieve both accuracy and interpretability is to learn a single tree on the output of a forest. Because it is a single tree, the decision making process will be more interpretable than a random forest. It will also be able to retain most of the accuracy gains from the forest, as the tree will be trained on examples classified by the forest along with the original example data (Domingos, 1998)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Question 2: Build a decision tree for classification, step by step, following the lecture notes. Note that the dataset has been slightly modified, so you will get a different tree than the one shown in the lecture notes.  (30 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MPG</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>HP</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>good</td>\n",
       "      <td>4</td>\n",
       "      <td>75</td>\n",
       "      <td>light</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bad</td>\n",
       "      <td>6</td>\n",
       "      <td>90</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bad</td>\n",
       "      <td>4</td>\n",
       "      <td>110</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bad</td>\n",
       "      <td>8</td>\n",
       "      <td>175</td>\n",
       "      <td>weighty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bad</td>\n",
       "      <td>6</td>\n",
       "      <td>95</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>bad</td>\n",
       "      <td>4</td>\n",
       "      <td>94</td>\n",
       "      <td>light</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>bad</td>\n",
       "      <td>4</td>\n",
       "      <td>95</td>\n",
       "      <td>light</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>bad</td>\n",
       "      <td>8</td>\n",
       "      <td>139</td>\n",
       "      <td>weighty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>bad</td>\n",
       "      <td>8</td>\n",
       "      <td>190</td>\n",
       "      <td>weighty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>bad</td>\n",
       "      <td>8</td>\n",
       "      <td>145</td>\n",
       "      <td>weighty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>bad</td>\n",
       "      <td>6</td>\n",
       "      <td>100</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>good</td>\n",
       "      <td>4</td>\n",
       "      <td>92</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>bad</td>\n",
       "      <td>6</td>\n",
       "      <td>100</td>\n",
       "      <td>weighty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>bad</td>\n",
       "      <td>8</td>\n",
       "      <td>170</td>\n",
       "      <td>weighty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>good</td>\n",
       "      <td>4</td>\n",
       "      <td>89</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>good</td>\n",
       "      <td>4</td>\n",
       "      <td>65</td>\n",
       "      <td>light</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>bad</td>\n",
       "      <td>6</td>\n",
       "      <td>85</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>good</td>\n",
       "      <td>4</td>\n",
       "      <td>81</td>\n",
       "      <td>light</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>bad</td>\n",
       "      <td>6</td>\n",
       "      <td>95</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>bad</td>\n",
       "      <td>4</td>\n",
       "      <td>93</td>\n",
       "      <td>light</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     MPG  cylinders   HP   weight\n",
       "0   good          4   75    light\n",
       "1    bad          6   90   medium\n",
       "2    bad          4  110   medium\n",
       "3    bad          8  175  weighty\n",
       "4    bad          6   95   medium\n",
       "5    bad          4   94    light\n",
       "6    bad          4   95    light\n",
       "7    bad          8  139  weighty\n",
       "8    bad          8  190  weighty\n",
       "9    bad          8  145  weighty\n",
       "10   bad          6  100   medium\n",
       "11  good          4   92   medium\n",
       "12   bad          6  100  weighty\n",
       "13   bad          8  170  weighty\n",
       "14  good          4   89   medium\n",
       "15  good          4   65    light\n",
       "16   bad          6   85   medium\n",
       "17  good          4   81    light\n",
       "18   bad          6   95   medium\n",
       "19   bad          4   93    light"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from io import StringIO\n",
    "thefile = StringIO('MPG,cylinders,HP,weight\\ngood,4,75,light\\nbad,6,90,medium\\nbad,4,110,medium\\nbad,8,175,weighty\\nbad,6,95,medium\\nbad,4,94,light\\nbad,4,95,light\\nbad,8,139,weighty\\nbad,8,190,weighty\\nbad,8,145,weighty\\nbad,6,100,medium\\ngood,4,92,medium\\nbad,6,100,weighty\\nbad,8,170,weighty\\ngood,4,89,medium\\ngood,4,65,light\\nbad,6,85,medium\\ngood,4,81,light\\nbad,6,95,medium\\nbad,4,93,light')\n",
    "df = pd.read_csv(thefile)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Please use numpy and pandas to do the computation for parts a) through f).  Do not use an existing decision tree implementation like sklearn for this question."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Start with the entire dataset and find the most common MPG value. (2 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bad'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['MPG'].mode()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def InformationGain(goodY,badY,goodN,badN):\n",
    "    def F(X,Y):\n",
    "        val1 = X*np.log2(1.*(X+Y)/X) if X>0 else 0\n",
    "        val2 = Y*np.log2(1.*(X+Y)/Y) if Y>0 else 0\n",
    "        return val1+val2\n",
    "    return (F(goodY+goodN,badY+badN)-F(goodY,badY)-F(goodN,badN)) / (goodY+goodN+badY+badN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Enumerate all the possible binary questions you could ask for each discrete-valued variable.  For each such split, compute the numbers of \"good\" and \"bad\" MPG vehicles in each of the two child nodes, and compute the information gain using the provided function above. (5 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information gain from weight is light decision: 0.0971071794515\n",
      "Information gain from weight is medium decision: 0.0\n",
      "Information gain from weight is weighty decision: 0.15307795339\n"
     ]
    }
   ],
   "source": [
    "# Weight variable\n",
    "\n",
    "good_Light = (df['MPG'][df['weight'] == 'light'] == 'good').sum()\n",
    "bad_Light = (df['MPG'][df['weight'] == 'light'] == 'bad').sum()\n",
    "good_NotLight = (df['MPG'][df['weight'] != 'light'] == 'good').sum()\n",
    "bad_NotLight = (df['MPG'][df['weight'] != 'light'] == 'bad').sum()\n",
    "\n",
    "print(\"Information gain from weight is light decision:\",InformationGain(good_Light,bad_Light,good_NotLight,bad_NotLight))\n",
    "\n",
    "good_Medium = (df['MPG'][df['weight'] == 'medium'] == 'good').sum()\n",
    "bad_Medium = (df['MPG'][df['weight'] == 'medium'] == 'bad').sum()\n",
    "good_NotMedium = (df['MPG'][df['weight'] != 'medium'] == 'good').sum()\n",
    "bad_NotMedium = (df['MPG'][df['weight'] != 'medium'] == 'bad').sum()\n",
    "\n",
    "print(\"Information gain from weight is medium decision:\",InformationGain(good_Medium,bad_Medium,good_NotMedium,bad_NotMedium))\n",
    "\n",
    "good_Weighty = (df['MPG'][df['weight'] == 'weighty'] == 'good').sum()\n",
    "bad_Weighty = (df['MPG'][df['weight'] == 'weighty'] == 'bad').sum()\n",
    "good_NotWeighty = (df['MPG'][df['weight'] != 'weighty'] == 'good').sum()\n",
    "bad_NotWeighty = (df['MPG'][df['weight'] != 'weighty'] == 'bad').sum()\n",
    "\n",
    "print(\"Information gain from weight is weighty decision:\",InformationGain(good_Weighty,bad_Weighty,good_NotWeighty,bad_NotWeighty))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information gain from 4 cylinders decision: 0.365293897532\n",
      "Information gain from 6 cylinders decision: 0.15307795339\n",
      "Information gain from 8 cylinders decision: 0.122556248918\n"
     ]
    }
   ],
   "source": [
    "# Cylinder variable\n",
    "\n",
    "good_4 = (df['MPG'][df['cylinders'] == 4] == 'good').sum()\n",
    "bad_4 = (df['MPG'][df['cylinders'] == 4] == 'bad').sum()\n",
    "good_Not4 = (df['MPG'][df['cylinders'] != 4] == 'good').sum()\n",
    "bad_Not4 = (df['MPG'][df['cylinders'] != 4] == 'bad').sum()\n",
    "\n",
    "print(\"Information gain from 4 cylinders decision:\",InformationGain(good_4,bad_4,good_Not4,bad_Not4))\n",
    "\n",
    "good_6 = (df['MPG'][df['cylinders'] == 6] == 'good').sum()\n",
    "bad_6 = (df['MPG'][df['cylinders'] == 6] == 'bad').sum()\n",
    "good_Not6 = (df['MPG'][df['cylinders'] != 6] == 'good').sum()\n",
    "bad_Not6 = (df['MPG'][df['cylinders'] != 6] == 'bad').sum()\n",
    "\n",
    "print(\"Information gain from 6 cylinders decision:\",InformationGain(good_6,bad_6,good_Not6,bad_Not6))\n",
    "\n",
    "good_8 = (df['MPG'][df['cylinders'] == 8] == 'good').sum()\n",
    "bad_8 = (df['MPG'][df['cylinders'] == 8] == 'bad').sum()\n",
    "good_Not8 = (df['MPG'][df['cylinders'] != 8] == 'good').sum()\n",
    "bad_Not8 = (df['MPG'][df['cylinders'] != 8] == 'bad').sum()\n",
    "\n",
    "print(\"Information gain from 8 cylinders decision:\",InformationGain(good_8,bad_8,good_Not8,bad_Not8))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Enumerate all the possible binary questions you could ask for the real-valued variable HP.  For each such split, compute the numbers of \"good\" and \"bad\" MPG vehicles in each of the two child nodes, and compute the information gain using the provided function above. (5 pts) \n",
    "\n",
    "NOTE: if you'd like, you can just use all midpoints between consecutive values of the sorted HP attribute.  You are not required to exclude provably suboptimal questions like we did in the lecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information gain from an HP of 65 is 0.0\n",
      "Information gain from an HP of 75 is 0.105914933394\n",
      "Information gain from an HP of 81 is 0.226257944976\n",
      "Information gain from an HP of 85 is 0.367102656103\n",
      "Information gain from an HP of 89 is 0.214170945008\n",
      "Information gain from an HP of 90 is 0.365776599471\n",
      "Information gain from an HP of 92 is 0.275926745594\n",
      "Information gain from an HP of 93 is 0.509185925461\n",
      "Information gain from an HP of 94 is 0.429504523289\n",
      "Information gain from an HP of 95 is 0.365293897532\n",
      "Information gain from an HP of 100 is 0.223356870468\n",
      "Information gain from an HP of 110 is 0.15307795339\n",
      "Information gain from an HP of 139 is 0.122556248918\n",
      "Information gain from an HP of 145 is 0.0944475384315\n",
      "Information gain from an HP of 170 is 0.0683942335509\n",
      "Information gain from an HP of 175 is 0.0441134636746\n",
      "Information gain from an HP of 190 is 0.0213774558499\n"
     ]
    }
   ],
   "source": [
    "hp_values = sorted(df['HP'].unique().tolist(), key=int)\n",
    "\n",
    "for i in hp_values:\n",
    "    goodY = (df['MPG'][df['HP'] >= i] == 'good').sum()\n",
    "    badY = (df['MPG'][df['HP'] >= i] == 'bad').sum()\n",
    "    goodN = (df['MPG'][df['HP'] < i] == 'good').sum()\n",
    "    badN = (df['MPG'][df['HP'] < i] == 'bad').sum()\n",
    "    \n",
    "    print(\"Information gain from an HP of\",i,\"is\", InformationGain(goodY,badY,goodN,badN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes results to over > 93 HP?: 0 and 13\n",
      "No results to over > 93 HP?: 5 and 2\n"
     ]
    }
   ],
   "source": [
    "goodY = (df['MPG'][df['HP'] >= 93] == 'good').sum()\n",
    "badY = (df['MPG'][df['HP'] >= 93] == 'bad').sum()\n",
    "\n",
    "goodN = (df['MPG'][df['HP'] < 93] == 'good').sum()\n",
    "badN = (df['MPG'][df['HP'] < 93] == 'bad').sum()\n",
    "print('Yes results to over > 93 HP?:',goodY,'and',badY)\n",
    "print('No results to over > 93 HP?:',goodN,'and',badN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) Based on your results for parts b and c, what is the optimal binary split of the data?  Of the two child nodes created by this split, which (if any) would require further partitioning? (4 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Part c showed the greatest information gain came from asking whether the HP is above 93. Further, the no results is not fully seperated, requiring further partitioning. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e) Repeat parts a through d until all training data points are perfectly classified by the resulting tree. (6 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MPG</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>HP</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>good</td>\n",
       "      <td>4</td>\n",
       "      <td>75</td>\n",
       "      <td>light</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bad</td>\n",
       "      <td>6</td>\n",
       "      <td>90</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>good</td>\n",
       "      <td>4</td>\n",
       "      <td>92</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>good</td>\n",
       "      <td>4</td>\n",
       "      <td>89</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>good</td>\n",
       "      <td>4</td>\n",
       "      <td>65</td>\n",
       "      <td>light</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>bad</td>\n",
       "      <td>6</td>\n",
       "      <td>85</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>good</td>\n",
       "      <td>4</td>\n",
       "      <td>81</td>\n",
       "      <td>light</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     MPG  cylinders  HP  weight\n",
       "0   good          4  75   light\n",
       "1    bad          6  90  medium\n",
       "11  good          4  92  medium\n",
       "14  good          4  89  medium\n",
       "15  good          4  65   light\n",
       "16   bad          6  85  medium\n",
       "17  good          4  81   light"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df = df[df['HP'] < 93]\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information gain from 8 cylinders decision: 0.863120568567\n"
     ]
    }
   ],
   "source": [
    "good2_4 = (result_df['MPG'][result_df['cylinders'] == 4] == 'good').sum()\n",
    "bad2_4 = (result_df['MPG'][result_df['cylinders'] == 4] == 'bad').sum()\n",
    "good2_Not4 = (result_df['MPG'][result_df['cylinders'] != 4] == 'good').sum()\n",
    "bad2_Not4 = (result_df['MPG'][result_df['cylinders'] != 4] == 'bad').sum()\n",
    "\n",
    "print(\"Information gain from 8 cylinders decision:\",InformationGain(good2_4,bad2_4,good2_Not4,bad2_Not4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f) Draw or show the final decision tree in a format of your choice.  The decision to make at each step and the predicted value at each leaf node must be clear. (4 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                          (( Is the HP > 93? ))\n",
    "                      yes /                   \\ no\n",
    "                         /                     \\\n",
    "                    (( Bad ))               (( Are there 4 cylinders? ))\n",
    "                                        yes /                          \\ no\n",
    "                                           /                            \\\n",
    "                                    (( Good ))                        (( Bad ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "g) Classify each of the following four vehicles as having \"good\" or \"bad\" fuel efficiency (miles per gallon).  Do this by hand using the tree structure learned in part f. (4 pts)\n",
    "\n",
    "?,8,70,light\n",
    "\n",
    "        1. Is the HP > 93?         --No\n",
    "        2. Is the cylinders = 4?   --No\n",
    "        Conclusion: Bad\n",
    "\n",
    "?,6,113,medium\n",
    "\n",
    "        1. Is the HP > 93?         --Yes\n",
    "        Conclusion: Bad\n",
    "\n",
    "?,4,83,weighty\n",
    "\n",
    "        1. Is the HP > 93?         --No\n",
    "        2. Is the cylinders = 4?   --Yes\n",
    "        Conclusion: Good\n",
    "\n",
    "?,4,95,weighty\n",
    "\n",
    "        1. Is the HP > 93?         --Yes\n",
    "        Conclusion: Bad\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3, Predicting burden of disease （40 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>FrxnPeaceIn10</th>\n",
       "      <th>ODA4H2OPcptaDol</th>\n",
       "      <th>RenewResm3PcptaYr</th>\n",
       "      <th>SustAccImprWatRur</th>\n",
       "      <th>SustAccImprWatUrb</th>\n",
       "      <th>SustAccImprSanRur</th>\n",
       "      <th>SustAccImprSanUrb</th>\n",
       "      <th>TotHlthExpPctofGDP</th>\n",
       "      <th>GenGovtPctofTotHlthExp</th>\n",
       "      <th>ExtResHlthPctTotExpHlth</th>\n",
       "      <th>PCptaGovtExpHlthAvgExcRt</th>\n",
       "      <th>GDPPCptaIntDol</th>\n",
       "      <th>AdultLtrcyRate</th>\n",
       "      <th>FemaleLtrcyRate</th>\n",
       "      <th>BurdenOfDisease</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.16</td>\n",
       "      <td>2986</td>\n",
       "      <td>0.10891</td>\n",
       "      <td>0.18812</td>\n",
       "      <td>0.049505</td>\n",
       "      <td>0.15842</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.395</td>\n",
       "      <td>0.4560</td>\n",
       "      <td>4</td>\n",
       "      <td>430</td>\n",
       "      <td>0.35644</td>\n",
       "      <td>0.20792</td>\n",
       "      <td>awful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Albania</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.58</td>\n",
       "      <td>13306</td>\n",
       "      <td>0.94059</td>\n",
       "      <td>0.98020</td>\n",
       "      <td>0.801980</td>\n",
       "      <td>0.98020</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.417</td>\n",
       "      <td>0.0340</td>\n",
       "      <td>49</td>\n",
       "      <td>6158</td>\n",
       "      <td>0.85644</td>\n",
       "      <td>0.78713</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Algeria</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.33</td>\n",
       "      <td>473</td>\n",
       "      <td>0.79208</td>\n",
       "      <td>0.91089</td>\n",
       "      <td>0.811880</td>\n",
       "      <td>0.98020</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.808</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>71</td>\n",
       "      <td>4860</td>\n",
       "      <td>0.69307</td>\n",
       "      <td>0.60396</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Country  FrxnPeaceIn10  ODA4H2OPcptaDol  RenewResm3PcptaYr  \\\n",
       "0  Afghanistan            0.1             0.16               2986   \n",
       "1      Albania            1.0             5.58              13306   \n",
       "2      Algeria            0.0             0.33                473   \n",
       "\n",
       "   SustAccImprWatRur  SustAccImprWatUrb  SustAccImprSanRur  SustAccImprSanUrb  \\\n",
       "0            0.10891            0.18812           0.049505            0.15842   \n",
       "1            0.94059            0.98020           0.801980            0.98020   \n",
       "2            0.79208            0.91089           0.811880            0.98020   \n",
       "\n",
       "   TotHlthExpPctofGDP  GenGovtPctofTotHlthExp  ExtResHlthPctTotExpHlth  \\\n",
       "0               0.065                   0.395                   0.4560   \n",
       "1               0.065                   0.417                   0.0340   \n",
       "2               0.041                   0.808                   0.0005   \n",
       "\n",
       "   PCptaGovtExpHlthAvgExcRt  GDPPCptaIntDol  AdultLtrcyRate  FemaleLtrcyRate  \\\n",
       "0                         4             430         0.35644          0.20792   \n",
       "1                        49            6158         0.85644          0.78713   \n",
       "2                        71            4860         0.69307          0.60396   \n",
       "\n",
       "  BurdenOfDisease  \n",
       "0           awful  \n",
       "1             low  \n",
       "2            high  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv(\"Burden of diarrheal illness by country.csv\")\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data dictionary\n",
    "\n",
    "NAME: Burden of diarrheal illness by country\n",
    "\n",
    "SIZE: 130 Countries, 16 Variables\n",
    "\n",
    "VARIABLE DESCRIPTIONS:\n",
    "\n",
    "Country: Country name\n",
    "\n",
    "FrxnPeaceIn10: Fraction of the past ten years in which a country has been at peace \n",
    "\n",
    "ODA4H2OPcptaDol: Per Capita Official Developmental Assistance for water projects\n",
    "\n",
    "RenewResm3PcptaYr: Renewable Water Resources in cubic meters per capita per year\n",
    "\n",
    "SustAccImprWatRur: Fraction of rural population with sustainable access to improved water\n",
    "\n",
    "SustAccImprWatUrb: Fraction of urban population with sustainable access to improved water\n",
    "\n",
    "SustAccImprSanRur: Fraction of rural population with sustainable access to improved sanitation\n",
    "\n",
    "SustAccImprSanUrb: Fraction of urban population with sustainable access to improved sanitation\n",
    "\n",
    "TotHlthExpPctofGDP: Fraction of a country's GDP devoted to health spending\n",
    "\n",
    "GenGovtPctofTotHlthExp: The fraction of total health expenditures for a country which is provided by the government\n",
    "\n",
    "ExtResHlthPctTotExpHlth: The fraction of total health expenditures for a country which is comes from sources external to the country\n",
    "\n",
    "PCptaGovtExpHlthAvgExcRt: Per Capita Government Health Expenditures at the average exchange rate\n",
    "\n",
    "GDPPCptaIntDol: Gross Domestic Product per capita in international dollars\n",
    "\n",
    "AdultLtrcyRate: Adult Literacy rate\n",
    "\n",
    "FemaleLtrcyRate: Female Literacy rate\n",
    "\n",
    "BurdenOfDisease: Our target variable for classification.  The burden of disease due to diarrheal illness, categorized into \"low\", \"medium\", \"high\", and \"awful\" quartiles.  For each country, we have estimates of the number of Disability-Adjusted Life Years lost per 1000 persons per year (DALYs) due to diarrheal illness.  Countries with \"low\" burden of disease have up to 2.75345 DALYs; countries with \"medium\" burden of disease have between 2.75345 and 8.2127 DALYs; countries with \"high\" burden of disease have between 8.2127 and 26.699 DALYs; and countries with \"awful\" burden of diease have more than 26.699 DALYs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your goal is to train a decision tree classifier for the attribute “BurdenOfDisease\" using all other variables (except country name) as features with sklearn.tree.DecisionTreeClassifier. \n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Please choose a train/test split and choose a hyper-parameter governing model simplicity, for example, the maximum tree depth or maximum number of leaf nodes. Then, fit your decision tree classifier (using the training set) for different values of this parameter and for each such value, record the corresponding classification accuracy on the test set. (10 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = data.replace({'awful': 0, 'low': 1, 'medium': 2, 'high': 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Country', 'FrxnPeaceIn10', 'ODA4H2OPcptaDol', 'RenewResm3PcptaYr',\n",
       "       'SustAccImprWatRur', 'SustAccImprWatUrb', 'SustAccImprSanRur',\n",
       "       'SustAccImprSanUrb', 'TotHlthExpPctofGDP', 'GenGovtPctofTotHlthExp',\n",
       "       'ExtResHlthPctTotExpHlth', 'PCptaGovtExpHlthAvgExcRt', 'GDPPCptaIntDol',\n",
       "       'AdultLtrcyRate', 'FemaleLtrcyRate', 'BurdenOfDisease'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    FrxnPeaceIn10  ODA4H2OPcptaDol  RenewResm3PcptaYr  SustAccImprWatRur  \\\n",
      "7             1.0             0.00                 66            0.85149   \n",
      "53            1.0             8.04             317000            0.82178   \n",
      "15            1.0             4.19               9345            0.89109   \n",
      "36            0.4             0.12              25183            0.28713   \n",
      "12            1.0             2.87              45564            0.59406   \n",
      "\n",
      "    SustAccImprWatUrb  SustAccImprSanRur  SustAccImprSanUrb  \\\n",
      "7             0.97030            0.99010            0.99010   \n",
      "53            0.82178            0.59406            0.85149   \n",
      "15            0.99010            0.24752            0.56436   \n",
      "36            0.82178            0.22772            0.42574   \n",
      "12            0.85149            0.69307            0.64356   \n",
      "\n",
      "    TotHlthExpPctofGDP  GenGovtPctofTotHlthExp  ExtResHlthPctTotExpHlth  \\\n",
      "7                0.064                   0.475                    0.002   \n",
      "53               0.048                   0.826                    0.032   \n",
      "15               0.056                   0.582                    0.029   \n",
      "36               0.040                   0.183                    0.151   \n",
      "12               0.031                   0.835                    0.186   \n",
      "\n",
      "    PCptaGovtExpHlthAvgExcRt  GDPPCptaIntDol  AdultLtrcyRate  FemaleLtrcyRate  \n",
      "7                        533           19930         0.94653          0.95545  \n",
      "53                        44            6198         0.97822          0.97525  \n",
      "15                       135            7344         0.79010          0.81584  \n",
      "36                         1             382         0.64851          0.54554  \n",
      "12                         9            2035         0.46535          0.33663  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# remove records with any missing values\n",
    "data=data.dropna()\n",
    "\n",
    "# target variable. \n",
    "y=data.loc[:,\"BurdenOfDisease\"]\n",
    "\n",
    "# Get the feature space\n",
    "X=data.loc[:,\"FrxnPeaceIn10\":\"FemaleLtrcyRate\"]\n",
    "#X=pd.get_dummies(X)\n",
    "\n",
    "# Split data into 70% train, 30% test\n",
    "X_train,X_test,y_train,y_test=train_test_split(X, y, test_size=0.3, random_state=999)\n",
    "print (X_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(130, 14)\n",
      "(130,)\n"
     ]
    }
   ],
   "source": [
    "print (X.shape)\n",
    "print (y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out of sample accuracy for depth 1 : 0.326923076923\n",
      "Out of sample accuracy for depth 2 : 0.480769230769\n",
      "Out of sample accuracy for depth 3 : 0.653846153846\n",
      "Out of sample accuracy for depth 4 : 0.557692307692\n",
      "Out of sample accuracy for depth 5 : 0.461538461538\n",
      "Out of sample accuracy for depth 6 : 0.653846153846\n",
      "Out of sample accuracy for depth 7 : 0.596153846154\n",
      "Out of sample accuracy for depth 8 : 0.596153846154\n",
      "Out of sample accuracy for depth 9 : 0.5\n",
      "Out of sample accuracy for depth 10 : 0.519230769231\n"
     ]
    }
   ],
   "source": [
    "OS = []\n",
    "\n",
    "for i in range(1,11):\n",
    "    dt = DecisionTreeClassifier(random_state = 999,max_depth = i)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.4, random_state = i)\n",
    "    dt.fit(X_train,y_train)\n",
    "    OS.append(dt.score(X_test,y_test))\n",
    "    print ('Out of sample accuracy for depth',i,':',dt.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Make a plot of accuracy vs. simplicity for different values of the hyper-parameter chosen in part a). That is, the x-axis should be hyper-parameter value (e.g. tree depth) and the y-axis should be accuracy. (10 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMcYnSxbGGGN8smRhjDHGJ0sWxhhjfPr/6MjvB9zRN0wAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x112afea90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pylab as plt\n",
    "\n",
    "plt.plot(range(1,11),OS)\n",
    "plt.xlabel('Tree Depth')\n",
    "plt.ylabel('Out of Sample Accuracy')\n",
    "plt.title('Accuracy vs. Simplicity')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Tune the hyper-parameter you choose in part a) by cross-validation using the training data. You can choose to use the GridSearchCV package from sklearn or write your own code to do cross-validation by spliting the training data into training and validation data. What is the out of sample accuracy after tuning the hyper-parameter? (10 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 5}\n",
      "0.365384615385\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'max_depth':range(1,11)}\n",
    "\n",
    "dt = DecisionTreeClassifier(random_state = 999)\n",
    "gs=GridSearchCV(dt,param_grid=param_grid,scoring='accuracy')\n",
    "rs=gs.fit(X_train,y_train)\n",
    "pred=rs.predict_proba(X_test)[:,1]\n",
    "print(rs.best_params_)\n",
    "print(accuracy_score(np.array(y_test),pred.round()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) Visualize a simple decision tree (e.g., with max_depth = 2 or 3) learned from the data.  To do so, given your decision tree dt, you can use the code below, then copy and paste the resulting output into http://www.webgraphviz.com.  Alternatively, if you have graphviz installed on your machine, you can use that. (5 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "digraph Tree {\n",
      "node [shape=box, style=\"filled, rounded\", color=\"black\", fontname=helvetica] ;\n",
      "edge [fontname=helvetica] ;\n",
      "0 [label=\"GDPPCptaIntDol <= 2349.5, samples = 78, value = [20, 20, 16, 22], class = 3\", fillcolor=\"#d739e509\"] ;\n",
      "1 [label=\"SustAccImprSanRur <= 0.4208, samples = 34, value = [20, 0, 0, 14], class = 0\", fillcolor=\"#e581394d\"] ;\n",
      "0 -> 1 [labeldistance=2.5, labelangle=45, headlabel=\"True\"] ;\n",
      "2 [label=\"ExtResHlthPctTotExpHlth <= 0.027, samples = 28, value = [20, 0, 0, 8], class = 0\", fillcolor=\"#e5813999\"] ;\n",
      "1 -> 2 ;\n",
      "3 [label=\"samples = 4, value = [0, 0, 0, 4], class = 3\", fillcolor=\"#d739e5ff\"] ;\n",
      "2 -> 3 ;\n",
      "4 [label=\"samples = 24, value = [20, 0, 0, 4], class = 0\", fillcolor=\"#e58139cc\"] ;\n",
      "2 -> 4 ;\n",
      "5 [label=\"samples = 6, value = [0, 0, 0, 6], class = 3\", fillcolor=\"#d739e5ff\"] ;\n",
      "1 -> 5 ;\n",
      "6 [label=\"GDPPCptaIntDol <= 8204.5, samples = 44, value = [0, 20, 16, 8], class = 1\", fillcolor=\"#47e53924\"] ;\n",
      "0 -> 6 [labeldistance=2.5, labelangle=-45, headlabel=\"False\"] ;\n",
      "7 [label=\"FemaleLtrcyRate <= 0.8109, samples = 28, value = [0, 5, 15, 8], class = 2\", fillcolor=\"#399de559\"] ;\n",
      "6 -> 7 ;\n",
      "8 [label=\"samples = 11, value = [0, 0, 3, 8], class = 3\", fillcolor=\"#d739e59f\"] ;\n",
      "7 -> 8 ;\n",
      "9 [label=\"samples = 17, value = [0, 5, 12, 0], class = 2\", fillcolor=\"#399de595\"] ;\n",
      "7 -> 9 ;\n",
      "10 [label=\"AdultLtrcyRate <= 0.799, samples = 16, value = [0, 15, 1, 0], class = 1\", fillcolor=\"#47e539ee\"] ;\n",
      "6 -> 10 ;\n",
      "11 [label=\"samples = 1, value = [0, 0, 1, 0], class = 2\", fillcolor=\"#399de5ff\"] ;\n",
      "10 -> 11 ;\n",
      "12 [label=\"samples = 15, value = [0, 15, 0, 0], class = 1\", fillcolor=\"#47e539ff\"] ;\n",
      "10 -> 12 ;\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "dt = DecisionTreeClassifier(max_depth=3) \n",
    "dt.fit(X_train,y_train)\n",
    "\n",
    "thestring=tree.export_graphviz(dt,out_file=None,\n",
    "                         feature_names=X_train.columns.values,  \n",
    "                         class_names=dt.classes_.astype('str'),  \n",
    "                         filled=True, rounded=True,  \n",
    "                         special_characters=True,impurity=False).replace(\"<br/>\",\", \").replace(\"&le;\",\"<=\").replace(\"=<\",\"=\\\"\").replace(\">,\",\"\\\",\")\n",
    "print(thestring)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4, Fit a random forest to the data from question 3 (20 pts)\n",
    "\n",
    "a) Please use the same test/train split from previous question and feel free to tune the hyper-parameters for Random Forest model using training data. The package from sklearn is here: http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html.\n",
    "Then please report your out of sample prediction result and compare this model's performance with 3c). (10 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.442307692308\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "rf = RandomForestClassifier(max_depth=3)\n",
    "rf.fit(X_train, y_train)\n",
    "pred=rf.predict_proba(X_test)[:,1]\n",
    "print (accuracy_score(y_test,pred.round()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "b) Write one paragraph comparing the results from those two models (Random Forest vs Decision Tree) in terms of both accuracy and interpretability. (10 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "    The results of the decision tree was an accuracy score of 0.36. While this was not high, the tree was highly interpretable, as with the limitation to a depth of three, graphviz displayed an easy to follow set of decisions. The tree begins by checking if the GDP of the country is over a certain threshold, and asks 3 more levels of questions to determine the class of burden of disease for a country, ranging from 0 to 4, or awful, low, medium, and high. The random forest model output an accuracy score of 0.44, a considerable improvement on the decision tree method in being able to accurately predict burden of disease. However, as this random forest is an ensemble method that averages predictors, understanding how the forest arrives to each specific classification is a much more complex question than going through a single tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
